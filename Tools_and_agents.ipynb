{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc45660",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Arxiv--Research\n",
    "## Tools creation\n",
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper,ArxivAPIWrapper\n",
    "from langchain_community.tools import YouTubeSearchTool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dc3992",
   "metadata": {},
   "source": [
    " Arxiv, Wikipedia & YouTube Search Tools\n",
    " This section initializes research-related tools:\n",
    " - ArxivQueryRun for academic paper search\n",
    " - WikipediaQueryRun for wiki-based information retrieval\n",
    " - YouTubeSearchTool for fetching relevant YouTube video results\n",
    " These tools will be used by the agent to gather external knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b69447d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run all this tools with Agents and LLM Models\n",
    "\n",
    "## Tools, LLM-->AgentExecutor\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047df2dc",
   "metadata": {},
   "source": [
    "### LLM Initialization (Groq)\n",
    "- Initialize the Groq Llama 3.1 model using the API key from environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c182102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001E3B13320D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001E3B11078D0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"llama-3.1-8b-instant\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fffabeb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Used the inbuilt tool of wikipedia\n",
    "api_wrapper_wiki=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=250)\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "500107a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv\n"
     ]
    }
   ],
   "source": [
    "api_wrapper_arxiv=ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=250)\n",
    "arxiv=ArxivQueryRun(api_wrapper=api_wrapper_arxiv)\n",
    "print(arxiv.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861fdc46",
   "metadata": {},
   "source": [
    "defines a YouTube search tool for LangChain using the @tool decorator. It takes a search query, retrieves up to 10 YouTube results using YoutubeSearch, extracts details such as title, channel, duration, and full video URL, and returns them in a structured dictionary format for use by an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7ca84c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_search import YoutubeSearch\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def youtube_search(query: str) -> dict:\n",
    "    \"\"\"\n",
    "    Search YouTube videos for the given query.\n",
    "    \"\"\"\n",
    "    raw = YoutubeSearch(query, max_results=10).to_dict()  # returns list\n",
    "\n",
    "    videos = []\n",
    "    for v in raw:\n",
    "        videos.append({\n",
    "            \"title\": v.get(\"title\"),\n",
    "            \"channel\": v.get(\"channel\"),\n",
    "            \"duration\": v.get(\"duration\"),\n",
    "            \"url\": f\"https://www.youtube.com{v.get('url_suffix')}\"\n",
    "        })\n",
    "\n",
    "    return {\"videos\": videos}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d19d24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.agents import create_tool_calling_agent\n",
    "from langchain.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12831111",
   "metadata": {},
   "source": [
    "These imports load the necessary components for building a tool-calling agent in LangChain. create_tool_calling_agent creates agents that can automatically decide when to use tools, @tool is used to define custom tools, and ChatPromptTemplate with MessagesPlaceholder helps construct structured chat prompts for the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5ef69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool\n",
    "@tool\n",
    "def multiply(a: int, b: int):\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256fb8ce",
   "metadata": {},
   "source": [
    "Configures a tool-enabled AI agent using a custom prompt and a set of tools (multiply, Wikipedia, and Arxiv). The prompt defines how the agent should behave, while the create_tool_calling_agent function connects the LLM with the available tools. The resulting agent can intelligently decide when to call these tools to answer user queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bcf80fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tools = [multiply,wiki,arxiv]\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Use tools ONLY when necessary.\"),\n",
    "    MessagesPlaceholder(\"messages\"),\n",
    "    MessagesPlaceholder(\"agent_scratchpad\") \n",
    "])\n",
    "\n",
    "# Agent\n",
    "agent = create_tool_calling_agent(\n",
    "    llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9733ab7",
   "metadata": {},
   "source": [
    "Creates an AgentExecutor, which is responsible for running the agent with the specified tools. It manages the full execution loopâ€”handling user inputs, deciding when to call tools, collecting intermediate steps, and producing the final response. Enabling verbose=True prints detailed execution traces for easier debugging and understanding of the agentâ€™s reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd4d6587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: message_formatter(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001E3B0800860>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001E3B0800860>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant. Use tools ONLY when necessary.'), additional_kwargs={}), MessagesPlaceholder(variable_name='messages'), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001E3B13320D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001E3B11078D0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'Multiply two numbers.', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| ToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[StructuredTool(name='multiply', description='Multiply two numbers.', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x000001E3B32E0E00>), WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'f:\\\\AgenticAI\\\\Workplace\\\\tf_env\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=250)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_classic.agents import AgentExecutor\n",
    "agent_executor=AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43f7872",
   "metadata": {},
   "source": [
    "This code sends a user queryâ€”â€œTell me about Langsmithâ€â€”to the agent via agent_executor.invoke(). The agent processes the message, optionally uses tools, and returns the final response. The result is stored in result1 and then displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cac3153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Langsmith'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of languag\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'LangChain'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of languag\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Langsmith'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of languag\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Langsmith vs Langchain'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mNo good Wikipedia Search Result was found\u001b[0m\u001b[32;1m\u001b[1;3mIt seems that there is not enough information available about 'Langsmith' in Wikipedia. If you'd like to know more about a specific topic, I'd be happy to try and help you find more information.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user', 'content': 'Tell me about Langsmith'}],\n",
       " 'output': \"It seems that there is not enough information available about 'Langsmith' in Wikipedia. If you'd like to know more about a specific topic, I'd be happy to try and help you find more information.\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1 = agent_executor.invoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Tell me about Langsmith\"}\n",
    "    ]\n",
    "})\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f886b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It seems that there is not enough information available about 'Langsmith' in Wikipedia. If you'd like to know more about a specific topic, I'd be happy to try and help you find more information.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64e6533a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'a': 2, 'b': 100}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m200\u001b[0m\u001b[32;1m\u001b[1;3mThe result of the multiplication is 200.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The result of the multiplication is 200.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#agent_executor.invoke({\"input\":\"Tell me about Langsmith\"})\n",
    "result2 = agent_executor.invoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"multiply 2 by 100\"}\n",
    "    ]\n",
    "})\n",
    "result2['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f1e63ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'Attention Is All You Need research paper'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mPublished: 2006-01-22\n",
      "Title: This paper has been withdrawn\n",
      "Authors: This paper has been withdrawn\n",
      "Summary: This paper has been withdrawn\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'Attention Is All You Need Vaswani et al 2017'}`\n",
      "responded: It seems that the paper 'Attention Is All You Need' is not found in the arXiv database. This is likely because the paper was actually published in 2017, not 2006. Let me try again with the correct year.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mPublished: 2015-06-15\n",
      "Title: On the sensitivity of extracting the astrophysical cross section factor of the 12C(a,g) reaction from existing data [Comment on Schuermann et al. Phys. Lett. B711(2012)35]\n",
      "Authors: Moshe Gai\n",
      "Summary: We address a conflict\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'Attention Is All You Need Vaswani et al 2017'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mPublished: 2015-06-15\n",
      "Title: On the sensitivity of extracting the astrophysical cross section factor of the 12C(a,g) reaction from existing data [Comment on Schuermann et al. Phys. Lett. B711(2012)35]\n",
      "Authors: Moshe Gai\n",
      "Summary: We address a conflict\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'Attention is all you need Vaswani 2017'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mPublished: 2017-11-29\n",
      "Title: The 4th Reactive Synthesis Competition (SYNTCOMP 2017): Benchmarks, Participants & Results\n",
      "Authors: Swen Jacobs, Nicolas Basset, Roderick Bloem, Romain Brenguier, Maximilien Colange, Peter Faymonville, Bernd Finkbeiner, A\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Attention Is All You Need'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Attention Is All You Need\n",
      "Summary: \"Attention Is All You Need\" is a 2017 landmark research paper in machine learning authored by eight scientists working at Google. The paper introduced a new deep learning architecture known as the transformer,\u001b[0m\u001b[32;1m\u001b[1;3mThe paper \"Attention Is All You Need\" was published in 2017 by Vaswani et al. It introduced a new neural network architecture called the transformer that is based entirely on self-attention mechanisms, eliminating the need for recurrent neural networks (RNNs) and convolutional neural networks (CNNs) in sequence-to-sequence models. This architecture has since become a widely used building block in many natural language processing (NLP) and other applications.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result3 = agent_executor.invoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Provide brife discription about the research paper 'Attention Is All You Need'\"}\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ff1406a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The paper \"Attention Is All You Need\" was published in 2017 by Vaswani et al. It introduced a new neural network architecture called the transformer that is based entirely on self-attention mechanisms, eliminating the need for recurrent neural networks (RNNs) and convolutional neural networks (CNNs) in sequence-to-sequence models. This architecture has since become a widely used building block in many natural language processing (NLP) and other applications.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d443b2a",
   "metadata": {},
   "source": [
    "These imports prepare the components needed to build a custom Retrieval-Augmented Generation (RAG) tool. The loader fetches web content, the text splitter breaks it into chunks, OpenAI embeddings convert text into vector representations, and FAISS stores and retrieves those vectors efficiently for semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1891a916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "## Custom tools[RAG Tool]\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ace11c7",
   "metadata": {},
   "source": [
    "code initializes a Hugging Face embedding model (all-MiniLM-L6-v2) using HuggingFaceEmbeddings. The model converts text into numerical vector embeddings, which are useful for tasks like semantic search, similarity comparison, and building RAG pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1d84c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\AgenticAI\\Workplace\\tf_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878d1da8",
   "metadata": {},
   "source": [
    "code loads content from the LangSmith documentation website using WebBaseLoader, splits the text into manageable chunks with RecursiveCharacterTextSplitter, and converts the chunks into vector embeddings using a Hugging Face model. These embeddings are stored in a FAISS vector database, which is then converted into a retriever for semantic search and RAG-based question answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c1ce56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E3B36149D0>, search_kwargs={})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader=WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs=loader.load()\n",
    "documents=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)\n",
    "vectordb=FAISS.from_documents(documents,HuggingFaceEmbeddings())\n",
    "retriever=vectordb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37b93606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith-search'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_classic.tools.retriever import create_retriever_tool\n",
    "retriever_tool=create_retriever_tool(retriever,\"langsmith-search\",\"Search any information about Langsmith \")\n",
    "\n",
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab48a73",
   "metadata": {},
   "source": [
    "This code wraps the FAISS-based retriever into a LangChain tool using create_retriever_tool. The resulting tool, named \"langsmith-search\", allows the agent to semantically search the LangSmith documentation whenever needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d2ef21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='langsmith-search', description='Search any information about Langsmith ', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001E3B1BAF4C0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E3B36149D0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001E3B1BAF600>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E3B36149D0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "003f4b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tools = [multiply,  arxiv, retriever_tool,wiki, youtube_search]\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. When a tool is used, include the tool results in the final answer.\"),\n",
    "    MessagesPlaceholder(\"messages\"),\n",
    "    MessagesPlaceholder(\"agent_scratchpad\") \n",
    "])\n",
    "\n",
    "# Agent\n",
    "agent = create_tool_calling_agent(\n",
    "    llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "058f237f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: message_formatter(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001E3B0800860>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001E3B0800860>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant. When a tool is used, include the tool results in the final answer.'), additional_kwargs={}), MessagesPlaceholder(variable_name='messages'), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001E3B13320D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001E3B11078D0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'Multiply two numbers.', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith-search', 'description': 'Search any information about Langsmith ', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'youtube_search', 'description': 'Search YouTube videos for the given query.', 'parameters': {'properties': {'query': {'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| ToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[StructuredTool(name='multiply', description='Multiply two numbers.', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x000001E3B32E0E00>), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250)), Tool(name='langsmith-search', description='Search any information about Langsmith ', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001E3B1BAF4C0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E3B36149D0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001E3B1BAF600>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E3B36149D0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content')), WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'f:\\\\AgenticAI\\\\Workplace\\\\tf_env\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=250)), StructuredTool(name='youtube_search', description='Search YouTube videos for the given query.', args_schema=<class 'langchain_core.utils.pydantic.youtube_search'>, func=<function youtube_search at 0x000001E40781E8E0>)])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "agent_executor=AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6000cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith-search` with `{'query': 'Langsmith'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLangSmith meets the highest standards of data security and privacy with HIPAA, SOC 2 Type 2, and GDPR compliance. For more information, see the Trust Center.\n",
      "â€‹Workflow\n",
      "LangSmith combines observability, evaluation, deployment, and platform setup in one integrated workflowâ€”from local development to production.\n",
      "\n",
      "LangSmith docs - Docs by LangChainSkip to main contentðŸš€ Share how you're building agents for a chance to win LangChain swag!Docs by LangChain home pageLangSmithSearch...âŒ˜KAsk AIGitHubTry LangSmithTry LangSmithSearch...NavigationLangSmith docsGet startedObservabilityEvaluationPrompt engineeringDeploymentAgent BuilderPlatform setupOverviewPlansCreate an account and API keyAccount administrationOverviewSet up a workspaceManage organizations using the APIManage billingSet up resource tagsUser managementReferenceLangSmith Python SDKLangSmith JS/TS SDKLangGraph Python SDKLangGraph JS/TS SDKLangSmith APIAPI reference for LangSmith DeploymentAdditional resourcesReleases & changelogsData managementAccess control & AuthenticationScalability & resilienceFAQsRegions FAQPricing FAQLangSmith docsCopy pageCopy pageLangSmith provides tools for developing, debugging, and deploying LLM applications.\n",
      "It helps you trace requests, evaluate outputs, test prompts, and manage deployments in one place.\n",
      "\n",
      "It helps you trace requests, evaluate outputs, test prompts, and manage deployments in one place.\n",
      "LangSmith is framework agnostic, so you can use it with or without LangChainâ€™s open-source libraries\n",
      "langchain and langgraph.\n",
      "Prototype locally, then move to production with integrated monitoring and evaluation to build more reliable AI systems.\n",
      "LangGraph Platform is now LangSmith Deployment. For more information, check out the Changelog.\n",
      "â€‹Get started\n",
      "Create an accountSign up at smith.langchain.com (no credit card required).\n",
      "You can log in with Google, GitHub, or email.Create an API keyGo to your Settings page â†’ API Keys â†’ Create API Key.\n",
      "Copy the key and save it securely.\n",
      "Once your account and API key are ready, choose a quickstart to begin building with LangSmith:\n",
      "\n",
      "Copy the key and save it securely.\n",
      "Once your account and API key are ready, choose a quickstart to begin building with LangSmith:\n",
      "ObservabilityGain visibility into every step your application takes to debug faster and improve reliability.Start tracingEvaluationMeasure and track quality over time to ensure your AI applications are consistent and trustworthy.Evaluate your appDeploymentDeploy your agents as Agent Servers, ready to scale in production.Deploy your agentsPlatform setupUse LangSmith in managed cloud, in a self-hosted environment, or hybrid to match your infrastructure and compliance needs.Choose how to set up LangSmithPrompt TestingIterate on prompts with built-in versioning and collaboration to ship improvements faster.Test your promptsStudioUse a visual interface to design, test, and refine applications end-to-end.Develop with Studio\u001b[0m\u001b[32;1m\u001b[1;3mThe provided information about Langsmith is a documentation and guide for the LangSmith platform, which is a tool for developing, debugging, and deploying large language model (LLM) applications. It provides features such as observability, evaluation, deployment, and platform setup, and is framework-agnostic, allowing users to use it with or without LangChain's open-source libraries.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user', 'content': 'Tell me about Langsmith'}],\n",
       " 'output': \"The provided information about Langsmith is a documentation and guide for the LangSmith platform, which is a tool for developing, debugging, and deploying large language model (LLM) applications. It provides features such as observability, evaluation, deployment, and platform setup, and is framework-agnostic, allowing users to use it with or without LangChain's open-source libraries.\"}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1_updated = agent_executor.invoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Tell me about Langsmith\"}\n",
    "    ]\n",
    "})\n",
    "result1_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "794f486a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `youtube_search` with `{'query': 'Langsmith videos'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m{'videos': [{'title': 'What Is LangSmith? Explained in 5 Minutes', 'channel': 'LangChain', 'duration': '5:25', 'url': 'https://www.youtube.com/watch?v=kYtnLaJeia8&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D'}, {'title': 'LangChain vs LangGraph vs LangSmith', 'channel': 'codebasics', 'duration': '10:16', 'url': 'https://www.youtube.com/watch?v=vJOGC8QJZJQ&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D'}, {'title': 'LangSmith in 10 Minutes', 'channel': 'LangChain', 'duration': '9:21', 'url': 'https://www.youtube.com/watch?v=jx7xuHlfsEQ&pp=ygUQTGFuZ3NtaXRoIHZpZGVvc9IHCQkLCgGHKiGM7w%3D%3D'}, {'title': 'LangSmith Crash Course | LangSmith Tutorial for Beginners | Observability in GenAI | CampusX', 'channel': 'CampusX', 'duration': '2:07:40', 'url': 'https://www.youtube.com/watch?v=4FFspU4riHk&t=113s&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D'}, {'title': 'LangGraph vs LangChain vs LangFlow vs LangSmith : Which One To Use & Why?', 'channel': 'FuturMinds', 'duration': '9:44', 'url': 'https://www.youtube.com/watch?v=ldBsvhjEREc&t=431s&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D'}, {'title': 'Langsmith LLMOPS Platform By Langchain-Debug ,Monitor And Build Production Grade LLM Application', 'channel': 'Krish Naik', 'duration': '22:07', 'url': 'https://www.youtube.com/watch?v=3Gcm27l-uyQ&pp=ygUQTGFuZ3NtaXRoIHZpZGVvc9IHCQkLCgGHKiGM7w%3D%3D'}, {'title': 'Getting Started with LangSmith (1/8): Tracing', 'channel': 'LangChain', 'duration': '8:21', 'url': 'https://www.youtube.com/watch?v=fA9b4D8IsPQ&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D'}, {'title': 'LangSmith Tutorial - LLM Evaluation for Beginners', 'channel': 'Dave Ebbelaar', 'duration': '36:10', 'url': 'https://www.youtube.com/watch?v=tFXm5ijih98&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D'}, {'title': 'Get Started with LangSmith Agent Builder', 'channel': 'LangChain', 'duration': '7:13', 'url': 'https://www.youtube.com/watch?v=97iiCrHPOpw&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D'}, {'title': 'Get Started with Insights Agent in LangSmith', 'channel': 'LangChain', 'duration': '5:26', 'url': 'https://www.youtube.com/watch?v=9aX8ETgSp0w&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D'}]}\u001b[0m\u001b[32;1m\u001b[1;3mThe Langsmith videos from YouTube along with their respective links are as follows:\n",
      "\n",
      "1. What Is LangSmith? Explained in 5 Minutes - https://www.youtube.com/watch?v=kYtnLaJeia8&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D\n",
      "2. LangChain vs LangGraph vs LangSmith - https://www.youtube.com/watch?v=vJOGC8QJZJQ&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D\n",
      "3. LangSmith in 10 Minutes - https://www.youtube.com/watch?v=jx7xuHlfsEQ&pp=ygUQTGFuZ3NtaXRoIHZpZGVvc9IHCQkLCgGHKiGM7w%3D%3D\n",
      "4. LangSmith Crash Course | LangSmith Tutorial for Beginners | Observability in GenAI | CampusX - https://www.youtube.com/watch?v=4FFspU4riHk&t=113s&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D\n",
      "5. LangGraph vs LangChain vs LangFlow vs LangSmith : Which One To Use & Why? - https://www.youtube.com/watch?v=ldBsvhjEREc&t=431s&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D\n",
      "6. Langsmith LLMOPS Platform By Langchain-Debug ,Monitor And Build Production Grade LLM Application - https://www.youtube.com/watch?v=3Gcm27l-uyQ&pp=ygUQTGFuZ3NtaXRoIHZpZGVvc9IHCQkLCgGHKiGM7w%3D%3D\n",
      "7. Getting Started with LangSmith (1/8): Tracing - https://www.youtube.com/watch?v=fA9b4D8IsPQ&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D\n",
      "8. LangSmith Tutorial - LLM Evaluation for Beginners - https://www.youtube.com/watch?v=tFXm5ijih98&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D\n",
      "9. Get Started with LangSmith Agent Builder - https://www.youtube.com/watch?v=97iiCrHPOpw&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D\n",
      "10. Get Started with Insights Agent in LangSmith - https://www.youtube.com/watch?v=9aX8ETgSp0w&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': 'Provide Langsmith videos from youtube along with respective links'}],\n",
       " 'output': 'The Langsmith videos from YouTube along with their respective links are as follows:\\n\\n1. What Is LangSmith? Explained in 5 Minutes - https://www.youtube.com/watch?v=kYtnLaJeia8&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D\\n2. LangChain vs LangGraph vs LangSmith - https://www.youtube.com/watch?v=vJOGC8QJZJQ&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D\\n3. LangSmith in 10 Minutes - https://www.youtube.com/watch?v=jx7xuHlfsEQ&pp=ygUQTGFuZ3NtaXRoIHZpZGVvc9IHCQkLCgGHKiGM7w%3D%3D\\n4. LangSmith Crash Course | LangSmith Tutorial for Beginners | Observability in GenAI | CampusX - https://www.youtube.com/watch?v=4FFspU4riHk&t=113s&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D\\n5. LangGraph vs LangChain vs LangFlow vs LangSmith : Which One To Use & Why? - https://www.youtube.com/watch?v=ldBsvhjEREc&t=431s&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D\\n6. Langsmith LLMOPS Platform By Langchain-Debug ,Monitor And Build Production Grade LLM Application - https://www.youtube.com/watch?v=3Gcm27l-uyQ&pp=ygUQTGFuZ3NtaXRoIHZpZGVvc9IHCQkLCgGHKiGM7w%3D%3D\\n7. Getting Started with LangSmith (1/8): Tracing - https://www.youtube.com/watch?v=fA9b4D8IsPQ&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D\\n8. LangSmith Tutorial - LLM Evaluation for Beginners - https://www.youtube.com/watch?v=tFXm5ijih98&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D\\n9. Get Started with LangSmith Agent Builder - https://www.youtube.com/watch?v=97iiCrHPOpw&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D\\n10. Get Started with Insights Agent in LangSmith - https://www.youtube.com/watch?v=9aX8ETgSp0w&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result4 = agent_executor.invoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Provide Langsmith videos from youtube along with respective links\"}\n",
    "    ]\n",
    "})\n",
    "result4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5c4576fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Langsmith videos from YouTube along with their respective links are as follows:\\n\\n1. What Is LangSmith? Explained in 5 Minutes - https://www.youtube.com/watch?v=kYtnLaJeia8&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D\\n2. LangChain vs LangGraph vs LangSmith - https://www.youtube.com/watch?v=vJOGC8QJZJQ&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D\\n3. LangSmith in 10 Minutes - https://www.youtube.com/watch?v=jx7xuHlfsEQ&pp=ygUQTGFuZ3NtaXRoIHZpZGVvc9IHCQkLCgGHKiGM7w%3D%3D\\n4. LangSmith Crash Course | LangSmith Tutorial for Beginners | Observability in GenAI | CampusX - https://www.youtube.com/watch?v=4FFspU4riHk&t=113s&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D\\n5. LangGraph vs LangChain vs LangFlow vs LangSmith : Which One To Use & Why? - https://www.youtube.com/watch?v=ldBsvhjEREc&t=431s&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D\\n6. Langsmith LLMOPS Platform By Langchain-Debug ,Monitor And Build Production Grade LLM Application - https://www.youtube.com/watch?v=3Gcm27l-uyQ&pp=ygUQTGFuZ3NtaXRoIHZpZGVvc9IHCQkLCgGHKiGM7w%3D%3D\\n7. Getting Started with LangSmith (1/8): Tracing - https://www.youtube.com/watch?v=fA9b4D8IsPQ&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D\\n8. LangSmith Tutorial - LLM Evaluation for Beginners - https://www.youtube.com/watch?v=tFXm5ijih98&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D\\n9. Get Started with LangSmith Agent Builder - https://www.youtube.com/watch?v=97iiCrHPOpw&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D\\n10. Get Started with Insights Agent in LangSmith - https://www.youtube.com/watch?v=9aX8ETgSp0w&pp=ygUQTGFuZ3NtaXRoIHZpZGVvcw%3D%3D'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result4['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bb7782",
   "metadata": {},
   "source": [
    "Package                  Version\n",
    "------------------------ -----------\n",
    "aiohappyeyeballs         2.6.1\n",
    "aiohttp                  3.13.2\n",
    "aiosignal                1.4.0\n",
    "annotated-types          0.7.0\n",
    "anyio                    4.11.0\n",
    "arxiv                    2.3.1\n",
    "asttokens                2.4.1\n",
    "attrs                    25.4.0\n",
    "beautifulsoup4           4.14.2\n",
    "bs4                      0.0.2\n",
    "certifi                  2025.11.12\n",
    "charset-normalizer       3.4.4\n",
    "colorama                 0.4.6\n",
    "comm                     0.2.1\n",
    "dataclasses-json         0.6.7\n",
    "debugpy                  1.8.1\n",
    "decorator                5.1.1\n",
    "distro                   1.9.0\n",
    "executing                2.0.1\n",
    "faiss-cpu                1.13.0\n",
    "feedparser               6.0.12\n",
    "filelock                 3.20.0\n",
    "frozenlist               1.8.0\n",
    "fsspec                   2025.10.0\n",
    "greenlet                 3.2.4\n",
    "groq                     0.36.0\n",
    "h11                      0.16.0\n",
    "httpcore                 1.0.9\n",
    "httpx                    0.28.1\n",
    "httpx-sse                0.4.3\n",
    "huggingface-hub          0.36.0\n",
    "idna                     3.11\n",
    "importlib_metadata       8.7.0\n",
    "ipykernel                7.1.0\n",
    "ipython                  9.7.0\n",
    "ipython_pygments_lexers  1.1.1\n",
    "jedi                     0.19.2\n",
    "Jinja2                   3.1.6\n",
    "jiter                    0.12.0\n",
    "joblib                   1.5.2\n",
    "jsonpatch                1.33\n",
    "jsonpointer              3.0.0\n",
    "jupyter_client           8.6.0\n",
    "jupyter_core             5.7.1\n",
    "langchain                1.0.8\n",
    "langchain-classic        1.0.0\n",
    "langchain-community      0.4.1\n",
    "langchain-core           1.1.0\n",
    "langchain-groq           1.0.1\n",
    "langchain-huggingface    1.0.1\n",
    "langchain-openai         1.0.3\n",
    "langchain-text-splitters 1.0.0\n",
    "langgraph                1.0.3\n",
    "langgraph-checkpoint     3.0.1\n",
    "langgraph-prebuilt       1.0.5\n",
    "langgraph-sdk            0.2.9\n",
    "langsmith                0.4.46\n",
    "MarkupSafe               3.0.3\n",
    "marshmallow              3.26.1\n",
    "matplotlib-inline        0.1.6\n",
    "mpmath                   1.3.0\n",
    "multidict                6.7.0\n",
    "mypy_extensions          1.1.0\n",
    "nest-asyncio             1.6.0\n",
    "networkx                 3.6\n",
    "numpy                    2.3.5\n",
    "openai                   2.8.1\n",
    "orjson                   3.11.4\n",
    "ormsgpack                1.12.0\n",
    "packaging                23.2\n",
    "parso                    0.8.3\n",
    "pillow                   12.0.0\n",
    "pip                      25.3\n",
    "platformdirs             4.5.0\n",
    "prompt-toolkit           3.0.43\n",
    "propcache                0.4.1\n",
    "psutil                   5.9.8\n",
    "pure-eval                0.2.2\n",
    "pydantic                 2.12.4\n",
    "pydantic_core            2.41.5\n",
    "pydantic-settings        2.12.0\n",
    "Pygments                 2.17.2\n",
    "python-dateutil          2.9.0.post0\n",
    "python-dotenv            1.2.1\n",
    "pywin32                  306\n",
    "PyYAML                   6.0.3\n",
    "pyzmq                    25.1.2\n",
    "regex                    2025.11.3\n",
    "requests                 2.32.5\n",
    "requests-toolbelt        1.0.0\n",
    "safetensors              0.7.0\n",
    "scikit-learn             1.7.2\n",
    "scipy                    1.16.3\n",
    "sentence-transformers    5.1.2\n",
    "setuptools               80.9.0\n",
    "sgmllib3k                1.0.0\n",
    "six                      1.16.0\n",
    "sniffio                  1.3.1\n",
    "soupsieve                2.8\n",
    "SQLAlchemy               2.0.44\n",
    "stack-data               0.6.3\n",
    "sympy                    1.14.0\n",
    "tenacity                 9.1.2\n",
    "threadpoolctl            3.6.0\n",
    "tiktoken                 0.12.0\n",
    "tokenizers               0.22.1\n",
    "torch                    2.9.1\n",
    "tornado                  6.4\n",
    "tqdm                     4.67.1\n",
    "traitlets                5.14.3\n",
    "transformers             4.57.1\n",
    "typing_extensions        4.15.0\n",
    "typing-inspect           0.9.0\n",
    "typing-inspection        0.4.2\n",
    "urllib3                  2.5.0\n",
    "wcwidth                  0.2.13\n",
    "wheel                    0.45.1\n",
    "wikipedia                1.4.0\n",
    "xxhash                   3.6.0\n",
    "yarl                     1.22.0\n",
    "youtube-search           2.1.2\n",
    "zipp                     3.23.0\n",
    "zstandard                0.25.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
